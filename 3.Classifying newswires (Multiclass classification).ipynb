{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying newswires:multiclass classification example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw how to classify vector inputs into two mutually exclusive classes using a densely connected neural network. But what happens when we have more than two classes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll build a network to classify **Reuters newswires** into **46 mutually exclusive topics**. \n",
    "\n",
    "* Because we have many classes, this problem is an instance of **multiclass classification**; \n",
    "* Because each data point should be classified into only one category,the problem is more specifically an instance of **single-label, multiclass classification**.\n",
    "* If each data point could belong to **multiple categories** (in this case, topics), we’d be facing a **multilabel, multiclass classification problem**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Reuters dataset\n",
    "\n",
    "We’ll work with the **Reuters dataset**, a set of short newswires and their topics, published by Reuters in 1986. It’s a simple, widely used toy dataset for text classification. There are 46 different topics; some topics are more represented than others, but each topic has at least 10 examples in the training set.\n",
    "\n",
    "Like **IMDB** and **MNIST**, the **Reuters dataset** comes packaged as part of Keras/Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the IMDB dataset, the argument `num_words=10000` restricts the data to the 10,000 most frequently occurring words found in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982,) (2246,)\n",
      "(8982,) (2246,)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape,test_data.shape)\n",
    "print(train_labels.shape,test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 8,982 training examples and 2,246 test examples.\n",
    "\n",
    "As with the **IMDB reviews**, each example is a list of integers (word indices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the data\n",
    "# One hot encoding (Manually)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize the Train and Test Labels:\n",
    "\n",
    "To vectorize the labels, there are two possibilities: \n",
    "\n",
    "1. We can cast the label list as an integer tensor, or \n",
    "2. We can use one-hot encoding. \n",
    "\n",
    "One-hot encoding is a widely used format for categorical data, also called **categorical encoding**. In this case, one-hot encoding of the labels consists of embedding each label as an all-zero vector with a 1 in the place of the label index. Here’s an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a built-in way to do this in Keras/Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Before Encoding\n",
      "\n",
      "3\n",
      "\n",
      "After Encoding\n",
      "\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBefore Encoding\\n\")\n",
    "print(train_labels[0])\n",
    "print(\"\\nAfter Encoding\\n\")\n",
    "print(one_hot_train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building our network\n",
    "\n",
    "This topic-classification problem looks similar to the movie-review classification problem: in both cases, we’re trying to classify short snippets of text. \n",
    "\n",
    "But there is a new constraint here: \n",
    "* the number of output classes has gone from 2 to 46. \n",
    "* The dimensionality of the output space is much larger.\n",
    "\n",
    "In a stack of Dense layers like we’ve been using, each layer can only access information present in the output of the previous layer. If one layer drops some information relevant to the classification problem, this information can never be recovered by later layers: each layer can potentially become an information bottleneck. \n",
    "\n",
    "In the previous file, we used 16-dimensional intermediate layers, but a 16-dimensional space may\n",
    "be too limited to learn to separate 46 different classes: such small layers may act as information bottlenecks, permanently dropping relevant information.\n",
    "\n",
    "This reason we’ll use larger layers. Let’s go with 64 units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two other things we should note about this architecture:\n",
    "\n",
    "1. We end the network with a Dense layer of size 46. This means for each input sample, the network will output a 46-dimensional vector. Each entry in this vector (each dimension) will encode a different output class.\n",
    "2. The last layer uses a `softmax` activation. We saw this pattern in the MNIST\n",
    "example. It means the network will output a probability distribution over the 46\n",
    "different output classes—for every input sample, the network will produce a 46-dimensional output vector, where `output[i]` is the probability that the sample belongs to class `i`. The 46 scores will sum to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **best loss function** to use in this case is **categorical_crossentropy**. It measures\n",
    "the distance between two probability distributions: \n",
    "* here, between the probability distribution output by the network and the true distribution of the labels. \n",
    "\n",
    "By minimizing the distance between these two distributions, we train the network to output something\n",
    "as close as possible to the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validating our approach\n",
    "# Let’s set apart 1,000 samples in the training data to use as a validation set.\n",
    "\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 10s 182ms/step - loss: 3.1329 - accuracy: 0.4164 - val_loss: 1.7859 - val_accuracy: 0.6210\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 1s 73ms/step - loss: 1.5503 - accuracy: 0.6839 - val_loss: 1.3345 - val_accuracy: 0.6950\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 82ms/step - loss: 1.0879 - accuracy: 0.7744 - val_loss: 1.1239 - val_accuracy: 0.7570\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.8532 - accuracy: 0.8227 - val_loss: 1.0293 - val_accuracy: 0.7840\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.6756 - accuracy: 0.8600 - val_loss: 0.9582 - val_accuracy: 0.7890\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 1s 75ms/step - loss: 0.5180 - accuracy: 0.8958 - val_loss: 0.9108 - val_accuracy: 0.8010\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 69ms/step - loss: 0.4190 - accuracy: 0.9168 - val_loss: 0.8932 - val_accuracy: 0.8080\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.3360 - accuracy: 0.9339 - val_loss: 0.8921 - val_accuracy: 0.8150\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.2732 - accuracy: 0.9403 - val_loss: 0.8734 - val_accuracy: 0.8270\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.2240 - accuracy: 0.9513 - val_loss: 0.8786 - val_accuracy: 0.8270\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.1928 - accuracy: 0.9544 - val_loss: 0.9381 - val_accuracy: 0.8080\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.1694 - accuracy: 0.9571 - val_loss: 0.9796 - val_accuracy: 0.8010\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.1493 - accuracy: 0.9610 - val_loss: 0.9314 - val_accuracy: 0.8170\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 77ms/step - loss: 0.1345 - accuracy: 0.9587 - val_loss: 0.9879 - val_accuracy: 0.8030\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 78ms/step - loss: 0.1303 - accuracy: 0.9620 - val_loss: 1.0153 - val_accuracy: 0.8040\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.1185 - accuracy: 0.9599 - val_loss: 0.9732 - val_accuracy: 0.8240\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 1s 68ms/step - loss: 0.1183 - accuracy: 0.9587 - val_loss: 1.0194 - val_accuracy: 0.8200\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.1073 - accuracy: 0.9628 - val_loss: 1.0929 - val_accuracy: 0.7950\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 1s 66ms/step - loss: 0.1167 - accuracy: 0.9573 - val_loss: 1.0953 - val_accuracy: 0.8080\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 1s 67ms/step - loss: 0.0948 - accuracy: 0.9660 - val_loss: 1.0388 - val_accuracy: 0.8120\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "\n",
    "history = model.fit(partial_x_train,partial_y_train,epochs=20,batch_size=512,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the training and validation loss\n",
    "\n",
    "Finally, let’s display its loss and accuracy curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf() # clear the figures\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network begins to overfit after nine epochs. Let’s train a new network from scratch for nine epochs and then evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "16/16 [==============================] - 10s 167ms/step - loss: 3.1711 - accuracy: 0.4073 - val_loss: 1.7972 - val_accuracy: 0.6320\n",
      "Epoch 2/9\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 1.5788 - accuracy: 0.6867 - val_loss: 1.3612 - val_accuracy: 0.7020\n",
      "Epoch 3/9\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 1.1255 - accuracy: 0.7642 - val_loss: 1.1610 - val_accuracy: 0.7570\n",
      "Epoch 4/9\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.8589 - accuracy: 0.8192 - val_loss: 1.0553 - val_accuracy: 0.7780\n",
      "Epoch 5/9\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.6749 - accuracy: 0.8593 - val_loss: 0.9924 - val_accuracy: 0.8060\n",
      "Epoch 6/9\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.5343 - accuracy: 0.8970 - val_loss: 0.9470 - val_accuracy: 0.8040\n",
      "Epoch 7/9\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.4342 - accuracy: 0.9165 - val_loss: 0.9336 - val_accuracy: 0.8080\n",
      "Epoch 8/9\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.3579 - accuracy: 0.9299 - val_loss: 0.9216 - val_accuracy: 0.8170\n",
      "Epoch 9/9\n",
      "16/16 [==============================] - 1s 70ms/step - loss: 0.2801 - accuracy: 0.9417 - val_loss: 0.9196 - val_accuracy: 0.8150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x235df7d2288>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retraining a model from scratch\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(partial_x_train,partial_y_train,epochs=9,batch_size=512,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 1s 4ms/step - loss: 0.9804 - accuracy: 0.7943\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9804096221923828, 0.7943009734153748]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach reaches an accuracy of **80%**. With a **balanced binary classification** problem, the accuracy reached by a purely random classifier would be **50%**. But in this case it’s closer to **19%** (see below code), so the results seem pretty good, at least when compared to a random baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0],test_labels_copy[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19011576135351738"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(test_labels_copy)\n",
    "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "float(np.sum(hits_array)) / len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for new data\n",
    "\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each entry in predictions is a vector of length 46:\n",
    "\n",
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The coefficients in this vector sum to 1:\n",
    "\n",
    "np.sum(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The largest entry is the predicted class—the class with the highest probability:\n",
    "\n",
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A different way to handle the labels and the loss\n",
    "\n",
    "We mentioned earlier that another way to encode the labels would be to cast them as an integer tensor, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_labels),type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing this approach would change is the **choice of the loss function**. \n",
    "* The loss function used in listing, **categorical_crossentropy**, expects the labels to follow a categorical encoding.\n",
    "* With integer labels, we should use **sparse_categorical_crossentropy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.compile(optimizer='rmsprop',loss='sparse_categorical_crossentropy',metrics=['acc'])`\n",
    "\n",
    "This new loss function is still mathematically the same as `categorical_crossentropy`;\n",
    "it just has a different interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The importance of having sufficiently large intermediate layers\n",
    "\n",
    "We mentioned earlier that because the final outputs are 46-dimensional, we should avoid intermediate layers with many fewer than 46 hidden units. \n",
    "\n",
    "Now let’s see what happens when we introduce an information bottleneck by having intermediate layers\n",
    "that are significantly less than 46-dimensional: for example, 4-dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 3s 35ms/step - loss: 3.6834 - accuracy: 0.0593 - val_loss: 3.2246 - val_accuracy: 0.3910\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 2s 31ms/step - loss: 2.9771 - accuracy: 0.3947 - val_loss: 2.4520 - val_accuracy: 0.4010 - accura\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 2.2385 - accuracy: 0.3995 - val_loss: 1.9903 - val_accuracy: 0.4220\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 1.7632 - accuracy: 0.5238 - val_loss: 1.7498 - val_accuracy: 0.5840\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 1.5749 - accuracy: 0.5980 - val_loss: 1.6731 - val_accuracy: 0.5930\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 1.4489 - accuracy: 0.6118 - val_loss: 1.6419 - val_accuracy: 0.5960\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 2s 30ms/step - loss: 1.3815 - accuracy: 0.6171 - val_loss: 1.6226 - val_accuracy: 0.5980\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 1.3130 - accuracy: 0.6217 - val_loss: 1.6071 - val_accuracy: 0.6110\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 1.2593 - accuracy: 0.6303 - val_loss: 1.6187 - val_accuracy: 0.6100\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 2s 29ms/step - loss: 1.2092 - accuracy: 0.6339 - val_loss: 1.6853 - val_accuracy: 0.6070\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 1.2238 - accuracy: 0.6352 - val_loss: 1.7326 - val_accuracy: 0.6120\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 1.1664 - accuracy: 0.6498 - val_loss: 1.6994 - val_accuracy: 0.6190\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 2s 29ms/step - loss: 1.1483 - accuracy: 0.6577 - val_loss: 1.7397 - val_accuracy: 0.6190\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 2s 30ms/step - loss: 1.1173 - accuracy: 0.6680 - val_loss: 1.8203 - val_accuracy: 0.6160\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 1.0958 - accuracy: 0.6702 - val_loss: 1.8458 - val_accuracy: 0.6150\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 1.0842 - accuracy: 0.6750 - val_loss: 1.8343 - val_accuracy: 0.6230\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 1.0742 - accuracy: 0.6811 - val_loss: 1.9285 - val_accuracy: 0.6060\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 1.0272 - accuracy: 0.6918 - val_loss: 1.9954 - val_accuracy: 0.6180\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 2s 27ms/step - loss: 1.0435 - accuracy: 0.6907 - val_loss: 1.9963 - val_accuracy: 0.6190\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 2s 28ms/step - loss: 1.0081 - accuracy: 0.7036 - val_loss: 2.0977 - val_accuracy: 0.6220\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x235dfa8e4c8>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(partial_x_train,partial_y_train,epochs=20,batch_size=128,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network now peaks at **62% validation accuracy**, an (81-62) **19% absolute drop**. \n",
    "* This drop is mostly due to the fact that we’re trying to compress a lot of information (enough information to recover the separation hyperplanes of 46 classes) into an intermediate space that is too low-dimensional. \n",
    "* The network is able to cram most of the necessary information into these eight dimensional representations, but not all of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further experiments\n",
    "* Try using larger or smaller layers: 32 units, 128 units, and so on.\n",
    "* We used two hidden layers. Now try using a single hidden layer, or three hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Here’s what we should take away from this example:\n",
    "* If we’re trying to classify data points among **N** classes, our network should end with a Dense layer of size **N**.\n",
    "* In a single-label, multiclass classification problem, our network should end with a **softmax activation** so that it will output a probability distribution over the **N** output classes.\n",
    "* **Categorical crossentropy** is almost always the loss function we should use for such problems. It minimizes the distance between the probability distributions output by the network and the true distribution of the targets.\n",
    "* There are two ways to handle labels in multiclass classification:\n",
    "    * Encoding the labels via categorical encoding (also known as one-hot encoding) and using **categorical_crossentropy as a loss function**.\n",
    "    * Encoding the labels as integers and using the **sparse_categorical_crossentropy loss function**.\n",
    "* If we need to classify data into a large number of categories, we should avoid creating information bottlenecks in our network due to intermediate layers that are too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
