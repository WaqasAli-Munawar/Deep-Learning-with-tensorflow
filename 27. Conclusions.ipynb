{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chapter covers\n",
    "\n",
    "* Important takeaways from this book\n",
    "* The limitations of deep learning\n",
    "* The future of deep learning, machine learning,\n",
    "and AI\n",
    "* Resources for learning further and working in\n",
    "the field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine learning** is a specific subfield of AI that aims at automatically developing\n",
    "programs (called **models**) purely from exposure to training data. This process of turning data into a program is called **learning**. Although machine learning has been\n",
    "around for a long time, it only started to take off in the 1990s.\n",
    "\n",
    "\n",
    "**Deep learning** is one of many branches of machine learning, where the models are\n",
    "long chains of geometric functions, applied one after the other. These operations are\n",
    "structured into modules called **layers**: \n",
    "* Deep-learning models are typically stacks of layers—or, more generally, graphs of layers. These layers are parameterized by **weights**,\n",
    "which are the parameters learned during training. The knowledge of a model is stored\n",
    "in its weights, and the process of **learning** consists of finding good values for these\n",
    "weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though deep learning is just one among many approaches to machine learning, it isn’t on an equal footing with the others. Deep learning is a breakout success.\n",
    "Here’s why. \n",
    "\n",
    "In the span of only a few years, deep learning has achieved tremendous breakthroughs across a wide range of tasks that have been historically perceived as\n",
    "extremely difficult for computers, especially in the area of machine perception:\n",
    "* Extracting useful information from images, videos, sound, and more. Given sufficient\n",
    "training data (in particular, training data appropriately labeled by humans), it’s possible to extract from perceptual data almost anything that a human could extract.\n",
    "Hence, it’s sometimes said that deep learning has **solved perception**, although that’s true\n",
    "only for a fairly narrow definition of **perception**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Key network architectures\n",
    "\n",
    "The three families of network architectures that we should be familiar with are \n",
    "* densely connected networks, \n",
    "* convolutional networks, and \n",
    "* recurrent networks. \n",
    "\n",
    "Each type of network is\n",
    "meant for a specific input modality: \n",
    "* A network architecture (dense, convolutional,\n",
    "recurrent) encodes **assumptions** about the structure of the data: a **hypothesis space** within\n",
    "which the search for a good model will proceed. Whether a given architecture will\n",
    "work on a given problem depends entirely on the match between the structure of the\n",
    "data and the assumptions of the network architecture.\n",
    " \n",
    "These different network types can easily be combined to achieve larger multimodal networks, much as we combine LEGO bricks. In a way, deep-learning layers are\n",
    "LEGO bricks for information processing. Here’s a quick overview of the mapping\n",
    "between input modalities and appropriate network architectures:\n",
    "\n",
    "* `Vector data`—Densely connected network (Dense layers).\n",
    "* `Image data`—2D convnets.\n",
    "* `Sound data` (for example, waveform)—Either 1D convnets (preferred) or RNNs.\n",
    "* `Text data`—Either 1D convnets (preferred) or RNNs.\n",
    "* `Timeseries data`—Either RNNs (preferred) or 1D convnets.\n",
    "* Other types of sequence data—Either RNNs or 1D convnets. Prefer RNNs if data\n",
    "ordering is strongly meaningful (for example, for timeseries, but not for text).\n",
    "* `Video data`—Either 3D convnets (if we need to capture motion effects) or a\n",
    "combination of a frame-level 2D convnet for feature extraction followed by\n",
    "either an RNN or a 1D convnet to process the resulting sequences.\n",
    "* `Volumetric data`—3D convnets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The space of possibilities\n",
    "\n",
    "* Mapping vector data to vector data\n",
    "    * `Predictive healthcare`—Mapping patient medical records to predictions of\n",
    "    patient outcomes\n",
    "    * `Behavioral targeting`—Mapping a set of website attributes with data on how\n",
    "    long a user will spend on the website\n",
    "    * `Product quality control`—Mapping a set of attributes relative to an instance of a\n",
    "    manufactured product with the probability that the product will fail by next\n",
    "    year\n",
    "\n",
    "\n",
    "* Mapping image data to vector data\n",
    "    * `Doctor assistant`—Mapping slides of medical images with a prediction about\n",
    "    the presence of a tumor\n",
    "    * `Self-driving vehicle`—Mapping car dash-cam video frames to steering wheel\n",
    "    angle commands\n",
    "    * `Board game AI`—Mapping Go and chess boards to the next player move\n",
    "    * `Diet helper`—Mapping pictures of a dish to its calorie count\n",
    "    * `Age prediction`—Mapping selfies to the age of the person\n",
    "\n",
    "\n",
    "* Mapping timeseries data to vector data\n",
    "    * `Weather prediction`—Mapping timeseries of weather data in a grid of locations\n",
    "    of weather data the following week at a specific location\n",
    "    * `Brain-computer interfaces`—Mapping timeseries of magnetoencephalogram\n",
    "    (MEG) data to computer commands\n",
    "    * `Behavioral targeting`—Mapping timeseries of user interactions on a website to\n",
    "    the probability that a user will buy something\n",
    "\n",
    "* Mapping text to text\n",
    "    * `Smart reply`—Mapping emails to possible one-line replies\n",
    "    * `Answering questions`—Mapping general-knowledge questions to answers\n",
    "    * `Summarization`—Mapping a long article to a short summary of the article\n",
    "\n",
    "* Mapping images to text\n",
    "    * `Captioning`—Mapping images to short captions describing the contents of\n",
    "    the images\n",
    "\n",
    "* Mapping text to images\n",
    "    * `Conditioned image generation`—Mapping a short text description to images\n",
    "    matching the description\n",
    "    * `Logo generation/selection`—Mapping the name and description of a company\n",
    "    to the company’s logo\n",
    "\n",
    "* Mapping images to images\n",
    "    * `Super-resolution`—Mapping downsized images to higher-resolution versions of\n",
    "    the same images\n",
    "    * `Visual depth sensing`—Mapping images of indoor environments to maps of\n",
    "    depth predictions\n",
    "\n",
    "* Mapping images and text to text\n",
    "    * `Visual QA`—Mapping images and natural-language questions about the contents of images to natural-language answers\n",
    "\n",
    "* Mapping video and text to text\n",
    "    * `Video QA`—Mapping short videos and natural-language questions about the\n",
    "    contents of videos to natural-language answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
